{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78930508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd2caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml_gpu.reader.gpu.cudf_reader import CudfReader\n",
    "from lightautoml_gpu.reader.base import PandasToPandasReader\n",
    "\n",
    "from lightautoml_gpu.transformers.base import SequentialTransformer\n",
    "\n",
    "from lightautoml_gpu.pipelines.utils import get_columns_by_role\n",
    "\n",
    "from lightautoml_gpu.transformers.gpu import numeric_gpu, categorical_gpu, datetime_gpu\n",
    "from lightautoml_gpu.transformers import numeric, categorical, datetime\n",
    "\n",
    "from lightautoml_gpu.tasks import Task\n",
    "from lightautoml_gpu.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dask.distributed import Client\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import cudf\n",
    "\n",
    "from lightautoml_gpu.dataset.roles import TargetRole\n",
    "\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d7afea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Airline  Flight AirportFrom AirportTo  DayOfWeek  Time  Length  Delay\n",
      "0      CO     269         SFO       IAH          3    15     205      1\n",
      "1      US    1558         PHX       CLT          3    15     222      1\n",
      "2      AA    2400         LAX       DFW          3    20     165      1\n",
      "3      AA    2466         SFO       DFW          3    20     195      1\n",
      "4      AS     108         ANC       SEA          3    30     202      0\n",
      "task type: binary\n"
     ]
    }
   ],
   "source": [
    "key = 'airlines'\n",
    "adv_roles = True\n",
    "args_fold = 2\n",
    "\n",
    "data_info = joblib.load(os.path.join(\"../../data/old_presets\", 'data_info.pkl'))[key]\n",
    "folds = joblib.load(os.path.join(\"../../data/old_presets\", 'folds', '{0}.pkl'.format(key)))\n",
    "\n",
    "read_csv_params = {}\n",
    "if 'read_csv_params' in data_info:\n",
    "    read_csv_params = {**read_csv_params, **data_info['read_csv_params']}\n",
    "\n",
    "data = pd.read_csv(os.path.join(\"../../data/old_presets/data\", data_info['path']), **read_csv_params)\n",
    "\n",
    "if 'drop' in data_info:\n",
    "    data.drop(data_info['drop'], axis=1, inplace=True)\n",
    "\n",
    "if 'class_map' in data_info:\n",
    "    data[data_info['target']] = data[data_info['target']].map(data_info['class_map']).values\n",
    "    assert data[data_info['target']].notnull().all(), 'Class mapping is set unproperly'\n",
    "\n",
    "print(data.head())\n",
    "print(\"task type:\", data_info['task_type'])\n",
    "\n",
    "roles = {TargetRole(): data_info['target']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c0d7c",
   "metadata": {},
   "source": [
    "## Imports (for potential use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a15c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from our package\n",
    "from lightautoml_gpu.automl.base import AutoML\n",
    "\n",
    "from lightautoml_gpu.automl.presets.gpu.tabular_gpu_presets import TabularAutoMLGPU, TabularUtilizedAutoMLGPU\n",
    "from lightautoml_gpu.tasks import Task\n",
    "\n",
    "from lightautoml_gpu.pipelines.features.gpu.lgb_pipeline_gpu import LGBSimpleFeaturesGPU, LGBAdvancedPipelineGPU\n",
    "from lightautoml_gpu.pipelines.features.gpu.linear_pipeline_gpu import LinearFeaturesGPU\n",
    "\n",
    "from lightautoml_gpu.pipelines.features.lgb_pipeline import LGBSimpleFeatures, LGBAdvancedPipeline\n",
    "from lightautoml_gpu.pipelines.features.linear_pipeline import LinearFeatures\n",
    "\n",
    "\n",
    "from lightautoml_gpu.ml_algo.gpu.boost_cb_gpu import BoostCBGPU\n",
    "from lightautoml_gpu.ml_algo.gpu.boost_xgb_gpu import BoostXGB\n",
    "from lightautoml_gpu.ml_algo.gpu.linear_gpu import LinearLBFGSGPU\n",
    "\n",
    "from lightautoml_gpu.ml_algo.boost_cb import BoostCB\n",
    "from lightautoml_gpu.ml_algo.linear_sklearn import LinearLBFGS\n",
    "\n",
    "\n",
    "from lightautoml_gpu.pipelines.ml.base import MLPipeline\n",
    "from lightautoml_gpu.pipelines.selection.importance_based import ModelBasedImportanceEstimator, ImportanceCutoffSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5da23f",
   "metadata": {},
   "source": [
    "## TabularAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71ba7253",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task(data_info['task_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14624311",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 4,\n",
    "    reader_params = {'n_jobs': 4, 'cv': 3, 'random_state': 42},\n",
    "    general_params = {'use_algos': ['linear_l2', 'cb', 'lgbm']}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b768794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cpu_fit_pred = automl.fit_predict(data[folds!=args_fold].reset_index().drop(['index'],axis=1), roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c9e7f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpu_pred = automl.predict(data[folds==args_fold].reset_index().drop(['index'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f432e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task(data_info['task_type'], device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a765c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_gpu = TabularAutoMLGPU(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 1,\n",
    "    reader_params = {'n_jobs': 1, 'cv': 3, 'random_state': 42},\n",
    "    general_params = {'use_algos': ['xgb']}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52f3b19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:45:06] Stdout logging level is INFO2.\n",
      "[13:45:06] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[13:45:06] Task: binary\n",
      "\n",
      "[13:45:06] Start automl preset with listed constraints:\n",
      "[13:45:06] - time: 3600.00 seconds\n",
      "[13:45:06] - CPU: 1 cores\n",
      "[13:45:06] - memory: 16 GB\n",
      "\n",
      "[13:45:06] Train data shape: (431506, 8)\n",
      "[13:45:07] Feats was rejected during automatic roles guess: []\n",
      "[13:45:07] Layer \u001b[1m1\u001b[0m train process start. Time left 3599.40 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "Warning: less than 75% gpu memory available for training. Free: 1229.3125 Total: 3912.8125\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:45:28] \u001b[1mSelector_CatBoostGPU\u001b[0m fitting and predicting completed\n",
      "[13:45:30] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_XGB\u001b[0m ...\n",
      "[13:45:30] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_XGB\u001b[0m (orig) =====\n",
      "[13:45:43] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_XGB\u001b[0m (orig) =====\n",
      "[13:45:52] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_XGB\u001b[0m (orig) =====\n",
      "[13:46:02] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_XGB\u001b[0m finished. score = \u001b[1m0.7095164060592651\u001b[0m\n",
      "[13:46:02] \u001b[1mLvl_0_Pipe_0_Mod_0_XGB\u001b[0m fitting and predicting completed\n",
      "[13:46:02] Time left 3544.12 secs\n",
      "\n",
      "[13:46:02] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[13:46:02] \u001b[1mAutoml preset training completed in 55.88 seconds\u001b[0m\n",
      "\n",
      "[13:46:02] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (3 averaged models Lvl_0_Pipe_0_Mod_0_XGB) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpu_fit_pred = automl_gpu.fit_predict(data[folds!=args_fold].reset_index().drop(['index'],axis=1), roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ad158c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_inf = automl_gpu.predict(data[folds==args_fold].reset_index().drop(['index'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7748506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_gpu.to_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf8c7fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_inf = automl_gpu.predict(data[folds==args_fold].reset_index().drop(['index'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70394263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/comm/ucx.py:61: UserWarning: A CUDA context for device 0 already exists on process ID 13767. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2022-12-10 13:46:08,210 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2022-12-10 13:46:08,210 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dashboard: http://127.0.0.1:8787/status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ucx://127.0.0.1:58973': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCUDACluster(rmm_managed_memory=True, CUDA_VISIBLE_DEVICES=\"0\",\n",
    "                               protocol=\"ucx\", enable_nvlink=True,\n",
    "                               memory_limit=\"8GB\")\n",
    "print(\"dashboard:\", cluster.dashboard_link)\n",
    "client = Client(cluster)\n",
    "client.run(cudf.set_allocator, \"managed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbf94656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:46:08] Stdout logging level is INFO2.\n",
      "[13:46:08] Task: binary\n",
      "\n",
      "[13:46:08] Start automl preset with listed constraints:\n",
      "[13:46:08] - time: 3600.00 seconds\n",
      "[13:46:08] - CPU: 1 cores\n",
      "[13:46:08] - memory: 16 GB\n",
      "\n",
      "[13:46:08] Train data shape: (431506, 8)\n",
      "[13:46:09] Feats was rejected during automatic roles guess: []\n",
      "[13:46:09] Layer \u001b[1m1\u001b[0m train process start. Time left 3599.32 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "Warning: less than 75% gpu memory available for training. Free: 1050.3125 Total: 3912.8125\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:46:30] \u001b[1mSelector_CatBoostGPU\u001b[0m fitting and predicting completed\n",
      "[13:46:32] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_XGB\u001b[0m ...\n",
      "[13:46:32] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 13:46:40,740 - distributed.worker - ERROR - Could not deserialize task ('_convert_datetime-c03464c8957edbdad7435988d78f4cd6', 0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker.py\", line 2200, in execute\n",
      "    function, args, kwargs = await self._maybe_deserialize_task(ts)\n",
      "  File \"/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker.py\", line 2173, in _maybe_deserialize_task\n",
      "    function, args, kwargs = _deserialize(*ts.run_spec)\n",
      "  File \"/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker.py\", line 2844, in _deserialize\n",
      "    function = loads_function(function)\n",
      "  File \"/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker.py\", line 2838, in loads_function\n",
      "    return pickle.loads(bytes_object)\n",
      "  File \"/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/protocol/pickle.py\", line 73, in loads\n",
      "    return pickle.loads(x)\n",
      "  File \"/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/cudf/core/abc.py\", line 188, in host_deserialize\n",
      "    frames = [\n",
      "  File \"/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/cudf/core/abc.py\", line 189, in <listcomp>\n",
      "    rmm.DeviceBuffer.to_device(f) if c else f\n",
      "  File \"device_buffer.pyx\", line 152, in rmm._lib.device_buffer.DeviceBuffer.to_device\n",
      "  File \"device_buffer.pyx\", line 346, in rmm._lib.device_buffer.to_device\n",
      "  File \"device_buffer.pyx\", line 89, in rmm._lib.device_buffer.DeviceBuffer.__cinit__\n",
      "MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /home/rishat/miniconda3/envs/rapids-22.10/include/rmm/mr/device/managed_memory_resource.hpp:74: cudaErrorMemoryAllocation out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:46:41] Model Lvl_0_Pipe_0_Mod_0_XGB failed during ml_algo.fit_predict call.\n",
      "\n",
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 13:46:41,097 - distributed.worker - ERROR - Could not deserialize task ('_convert_datetime-0ecfa0f6482f4b864b5aef5ea7ea34a0', 0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker.py\", line 2200, in execute\n",
      "    function, args, kwargs = await self._maybe_deserialize_task(ts)\n",
      "  File \"/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker.py\", line 2173, in _maybe_deserialize_task\n",
      "    function, args, kwargs = _deserialize(*ts.run_spec)\n",
      "  File \"/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker.py\", line 2844, in _deserialize\n",
      "    function = loads_function(function)\n",
      "  File \"/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker.py\", line 2838, in loads_function\n",
      "    return pickle.loads(bytes_object)\n",
      "  File \"/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/protocol/pickle.py\", line 73, in loads\n",
      "    return pickle.loads(x)\n",
      "  File \"/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/cudf/core/abc.py\", line 188, in host_deserialize\n",
      "    frames = [\n",
      "  File \"/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/cudf/core/abc.py\", line 189, in <listcomp>\n",
      "    rmm.DeviceBuffer.to_device(f) if c else f\n",
      "  File \"device_buffer.pyx\", line 152, in rmm._lib.device_buffer.DeviceBuffer.to_device\n",
      "  File \"device_buffer.pyx\", line 346, in rmm._lib.device_buffer.to_device\n",
      "  File \"device_buffer.pyx\", line 89, in rmm._lib.device_buffer.DeviceBuffer.__cinit__\n",
      "MemoryError: std::bad_alloc: out_of_memory: CUDA error at: /home/rishat/miniconda3/envs/rapids-22.10/include/rmm/mr/device/managed_memory_resource.hpp:74: cudaErrorMemoryAllocation out of memory\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Pipeline finished with 0 models for some reason.\nProbably one or more models failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m task \u001b[38;5;241m=\u001b[39m Task(data_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask_type\u001b[39m\u001b[38;5;124m'\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmgpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m automl_mgpu \u001b[38;5;241m=\u001b[39m TabularAutoMLGPU(\n\u001b[1;32m      4\u001b[0m     task \u001b[38;5;241m=\u001b[39m task, \n\u001b[1;32m      5\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3600\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     client \u001b[38;5;241m=\u001b[39m client\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m mgpu_fit_pred \u001b[38;5;241m=\u001b[39m \u001b[43mautoml_mgpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfolds\u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43margs_fold\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroles\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mroles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml_gpu/automl/presets/gpu/tabular_gpu_presets.py:591\u001b[0m, in \u001b[0;36mTabularAutoMLGPU.fit_predict\u001b[0;34m(self, train_data, roles, train_features, cv_iter, valid_data, valid_features, log_file, verbose, return_numpy)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    587\u001b[0m     data, _ \u001b[38;5;241m=\u001b[39m read_data(\n\u001b[1;32m    588\u001b[0m         valid_data, valid_features, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcpu_limit, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_csv_params\n\u001b[1;32m    589\u001b[0m     )\n\u001b[0;32m--> 591\u001b[0m oof_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTabularAutoMLGPU\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__bases__\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_numpy:\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m oof_pred\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml_gpu/automl/presets/base.py:205\u001b[0m, in \u001b[0;36mAutoMLPreset.fit_predict\u001b[0;34m(self, train_data, roles, train_features, cv_iter, valid_data, valid_features, verbose)\u001b[0m\n\u001b[1;32m    202\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- memory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory_limit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimer\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m--> 205\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\x1b\u001b[39;00m\u001b[38;5;124m[1mAutoml preset training completed in \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;130;01m\\x1b\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimer\u001b[38;5;241m.\u001b[39mtime_spent))\n\u001b[1;32m    216\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel description:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_model_str_desc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml_gpu/automl/base.py:223\u001b[0m, in \u001b[0;36mAutoML.fit_predict\u001b[0;34m(self, train_data, roles, train_features, cv_iter, valid_data, valid_features, verbose)\u001b[0m\n\u001b[1;32m    217\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;130;01m\\x1b\u001b[39;00m\u001b[38;5;124m[1m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleven_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\x1b\u001b[39;00m\u001b[38;5;124m[0m train process start. Time left \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimer\u001b[38;5;241m.\u001b[39mtime_left\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m secs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m )\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, ml_pipe \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(level):\n\u001b[0;32m--> 223\u001b[0m     pipe_pred \u001b[38;5;241m=\u001b[39m \u001b[43mml_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_valid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     level_predictions\u001b[38;5;241m.\u001b[39mappend(pipe_pred)\n\u001b[1;32m    225\u001b[0m     pipes\u001b[38;5;241m.\u001b[39mappend(ml_pipe)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/lightautoml_gpu/pipelines/ml/base.py:162\u001b[0m, in \u001b[0;36mMLPipeline.fit_predict\u001b[0;34m(self, train_valid)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mml_algos\u001b[38;5;241m.\u001b[39mappend(ml_algo)\n\u001b[1;32m    160\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mappend(preds)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mlen\u001b[39m(predictions) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    164\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline finished with 0 models for some reason.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mProbably one or more models failed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m predictions \u001b[38;5;241m=\u001b[39m concatenate(predictions)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ml_algos\n",
      "\u001b[0;31mAssertionError\u001b[0m: Pipeline finished with 0 models for some reason.\nProbably one or more models failed"
     ]
    }
   ],
   "source": [
    "task = Task(data_info['task_type'], device='mgpu')\n",
    "\n",
    "automl_mgpu = TabularAutoMLGPU(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 1,\n",
    "    reader_params = {'n_jobs': 1, 'cv': 3, 'random_state': 42, 'npartitions': 2},\n",
    "    general_params = {'use_algos': ['xgb']},\n",
    "    client = client\n",
    ")\n",
    "\n",
    "mgpu_fit_pred = automl_mgpu.fit_predict(data[folds!=args_fold].reset_index().drop(['index'],axis=1), roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2962d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgpu_pred = automl_mgpu.predict(data[folds==args_fold].reset_index().drop(['index'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9af169",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cpu_inf.data.T)\n",
    "print()\n",
    "print(gpu_inf.data.T)\n",
    "print()\n",
    "print(cpu_pred.data.T)\n",
    "print()\n",
    "print(mgpu_pred.data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507aa230",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cpu_fit_pred.data.T)\n",
    "print()\n",
    "print(gpu_fit_pred.data.T)\n",
    "print()\n",
    "print(mgpu_fit_pred.data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a422d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_mgpu.to_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f59447",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgpu_inf = automl_mgpu.predict(data[folds==args_fold].reset_index().drop(['index'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6b02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mgpu_inf.data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eb57a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_mgpu.levels[0][0].ml_algos[0].get_features_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322f920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1dd94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa42bfea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23960d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad26c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d0758d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76cca8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0e779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660d7bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4509b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af90c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.10",
   "language": "python",
   "name": "rapids-22.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
