{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78930508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "a = os.environ['OMP_NUM_THREADS'] = \"8\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd2caae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level \"INFO2: 17\" already defined, skipping...\n",
      "Level \"INFO3: 13\" already defined, skipping...\n"
     ]
    }
   ],
   "source": [
    "from lightautoml_gpu.reader.gpu.cudf_reader import CudfReader\n",
    "from lightautoml_gpu.reader.base import PandasToPandasReader\n",
    "\n",
    "from lightautoml_gpu.transformers.base import SequentialTransformer\n",
    "\n",
    "from lightautoml_gpu.pipelines.utils import get_columns_by_role\n",
    "\n",
    "from lightautoml_gpu.transformers.gpu import numeric_gpu, categorical_gpu, datetime_gpu\n",
    "from lightautoml_gpu.transformers import numeric, categorical, datetime\n",
    "\n",
    "from lightautoml_gpu.tasks import Task\n",
    "from lightautoml_gpu.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4befdbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/small_new/multioutput/ENB2012_data.csv')\n",
    "\n",
    "tr_data, te_data = train_test_split(\n",
    "    data, \n",
    "    test_size=0.2,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "roles = {\n",
    "    \"target\": {'Y1', 'Y2'},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f73a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_roles = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a15c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from our package\n",
    "from lightautoml_gpu.automl.base import AutoML\n",
    "\n",
    "\n",
    "from lightautoml_gpu.pipelines.features.gpu.lgb_pipeline_gpu import LGBSimpleFeaturesGPU, LGBAdvancedPipelineGPU\n",
    "from lightautoml_gpu.pipelines.features.gpu.linear_pipeline_gpu import LinearFeaturesGPU\n",
    "\n",
    "from lightautoml_gpu.pipelines.features.lgb_pipeline import LGBSimpleFeatures, LGBAdvancedPipeline\n",
    "from lightautoml_gpu.pipelines.features.linear_pipeline import LinearFeatures\n",
    "\n",
    "\n",
    "from lightautoml_gpu.ml_algo.gpu.boost_cb_gpu import BoostCBGPU\n",
    "from lightautoml_gpu.ml_algo.gpu.boost_xgb_gpu import BoostXGB\n",
    "from lightautoml_gpu.ml_algo.gpu.linear_gpu import LinearLBFGSGPU\n",
    "\n",
    "from lightautoml_gpu.ml_algo.boost_cb import BoostCB\n",
    "from lightautoml_gpu.ml_algo.linear_sklearn import LinearLBFGS\n",
    "from lightautoml_gpu.ml_algo.linear_sklearn import LinearL1CD\n",
    "\n",
    "\n",
    "from lightautoml_gpu.pipelines.ml.base import MLPipeline\n",
    "from lightautoml_gpu.pipelines.selection.importance_based import ModelBasedImportanceEstimator, ImportanceCutoffSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5da23f",
   "metadata": {},
   "source": [
    "## TabularAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71ba7253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi:reg isn`t supported in lgb\n",
      "[12:23:44] CatBoost supports only MultiRMSE metric and loss for multi:reg task.\n"
     ]
    }
   ],
   "source": [
    "task = Task('multi:reg', loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14624311",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 4,\n",
    "    reader_params = {'n_jobs': 4, 'cv': 3, 'random_state': 42},\n",
    "    general_params = {'use_algos': [['linear_l2', 'cb']]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b768794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:23:44] Stdout logging level is INFO2.\n",
      "[12:23:44] Task: multi:reg\n",
      "\n",
      "[12:23:44] Start automl preset with listed constraints:\n",
      "[12:23:44] - time: 3600.00 seconds\n",
      "[12:23:44] - CPU: 4 cores\n",
      "[12:23:44] - memory: 16 GB\n",
      "\n",
      "[12:23:44] \u001b[1mTrain data shape: (768, 10)\u001b[0m\n",
      "\n",
      "[12:23:54] Feats was rejected during automatic roles guess: []\n",
      "[12:23:54] Layer \u001b[1m1\u001b[0m train process start. Time left 3589.25 secs\n",
      "[12:23:54] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[12:23:54] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[12:23:55] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[12:23:55] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[12:23:55] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-2.1695349167287348\u001b[0m\n",
      "[12:23:55] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[12:23:55] Time left 3588.39 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:23:56] \u001b[1mSelector_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:23:56] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m ...\n",
      "[12:23:56] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:23:56] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:23:56] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/catboost/core.py:1419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:23:57] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m finished. score = \u001b[1m-0.3494882974897825\u001b[0m\n",
      "[12:23:57] \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoost\u001b[0m fitting and predicting completed\n",
      "[12:23:57] Time left 3586.97 secs\n",
      "\n",
      "[12:23:57] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[12:23:57] Blending: optimization starts with equal weights and score \u001b[1m-1.1414352590714898\u001b[0m\n",
      "[12:23:57] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.3494882974897825\u001b[0m, weights = \u001b[1m[0. 1.]\u001b[0m\n",
      "[12:23:57] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.3494882974897825\u001b[0m, weights = \u001b[1m[0. 1.]\u001b[0m\n",
      "[12:23:57] Blending: no score update. Terminated\n",
      "\n",
      "[12:23:57] \u001b[1mAutoml preset training completed in 13.04 seconds\u001b[0m\n",
      "\n",
      "[12:23:57] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (3 averaged models Lvl_0_Pipe_1_Mod_0_CatBoost) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_pred = automl.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "535dcbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml_gpu.automl.presets.gpu.tabular_gpu_presets import TabularAutoMLGPU, TabularUtilizedAutoMLGPU\n",
    "from lightautoml_gpu.tasks import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f432e058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi:reg isn`t supported in lgb\n"
     ]
    }
   ],
   "source": [
    "task = Task('multi:reg', loss = 'mse', device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a765c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_gpu = TabularAutoMLGPU(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 1,\n",
    "    reader_params = {'n_jobs': 1, 'cv': 3, 'random_state': 42},\n",
    "    general_params = {'use_algos': [['xgb', 'linear_l2', 'pb']]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52f3b19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:22:21] Stdout logging level is INFO2.\n",
      "[12:22:21] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[12:22:21] Task: multi:reg\n",
      "\n",
      "[12:22:21] Start automl preset with listed constraints:\n",
      "[12:22:21] - time: 3600.00 seconds\n",
      "[12:22:21] - CPU: 1 cores\n",
      "[12:22:21] - memory: 16 GB\n",
      "\n",
      "[12:22:21] Train data shape: (768, 10)\n",
      "[12:22:21] Feats was rejected during automatic roles guess: []\n",
      "[12:22:21] Layer \u001b[1m1\u001b[0m train process start. Time left 3599.54 secs\n",
      "[12:22:21] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[12:22:21] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[12:22:24] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[12:22:25] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[12:22:26] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-2.178004495278001\u001b[0m\n",
      "[12:22:26] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[12:22:26] Time left 3595.18 secs\n",
      "\n",
      "[12:22:28] Stdout logging level is INFO.\n",
      "[12:22:28] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[12:22:28] Iter 0; Sample 0, rmse = 9.208333456027422; \n",
      "[12:22:28] Iter 100; Sample 0, rmse = 2.1064524694255677; \n",
      "[12:22:29] Iter 200; Sample 0, rmse = 1.1985701648367715; \n",
      "[12:22:29] Iter 300; Sample 0, rmse = 1.0169535098827511; \n",
      "[12:22:30] Iter 400; Sample 0, rmse = 0.9886446557923608; \n",
      "[12:22:30] Iter 500; Sample 0, rmse = 0.9608381677417106; \n",
      "[12:22:30] Iter 600; Sample 0, rmse = 0.933744811069809; \n",
      "[12:22:31] Iter 700; Sample 0, rmse = 0.9170049569569286; \n",
      "[12:22:31] Iter 800; Sample 0, rmse = 0.9014818747686486; \n",
      "[12:22:32] Iter 900; Sample 0, rmse = 0.8883775448671676; \n",
      "[12:22:32] Iter 1000; Sample 0, rmse = 0.8791765960242034; \n",
      "[12:22:32] Iter 1100; Sample 0, rmse = 0.8685541009891209; \n",
      "[12:22:33] Iter 1200; Sample 0, rmse = 0.8605944496882302; \n",
      "[12:22:33] Iter 1300; Sample 0, rmse = 0.8545998435104775; \n",
      "[12:22:34] Iter 1400; Sample 0, rmse = 0.8396436804752423; \n",
      "[12:22:34] Iter 1500; Sample 0, rmse = 0.8313738472626893; \n",
      "[12:22:35] Iter 1600; Sample 0, rmse = 0.8214293818548678; \n",
      "[12:22:35] Iter 1700; Sample 0, rmse = 0.8185097530971529; \n",
      "[12:22:36] Iter 1800; Sample 0, rmse = 0.8152675103480838; \n",
      "[12:22:36] Iter 1900; Sample 0, rmse = 0.8107491759651649; \n",
      "[12:22:37] Iter 2000; Sample 0, rmse = 0.8071152496537191; \n",
      "[12:22:37] Iter 2100; Sample 0, rmse = 0.8044310347111039; \n",
      "[12:22:38] Iter 2200; Sample 0, rmse = 0.8019071837584502; \n",
      "[12:22:38] Iter 2300; Sample 0, rmse = 0.8008388638819308; \n",
      "[12:22:39] Iter 2400; Sample 0, rmse = 0.7961946277327414; \n",
      "[12:22:39] Iter 2500; Sample 0, rmse = 0.7926286348452619; \n",
      "[12:22:40] Iter 2600; Sample 0, rmse = 0.7862668009216519; \n",
      "[12:22:40] Iter 2700; Sample 0, rmse = 0.7822094165920556; \n",
      "[12:22:41] Iter 2800; Sample 0, rmse = 0.7776327718921523; \n",
      "[12:22:41] Iter 2900; Sample 0, rmse = 0.7754032814232555; \n",
      "[12:22:42] Iter 2999; Sample 0, rmse = 0.7727038962257449; \n",
      "[12:22:43] \u001b[1mSelector_PB\u001b[0m fitting and predicting completed\n",
      "[12:22:44] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m ...\n",
      "[12:22:44] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n",
      "[12:22:48] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n",
      "[12:22:54] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n",
      "[12:22:58] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m finished. score = \u001b[1m-0.5334486607213815\u001b[0m\n",
      "[12:22:58] \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m fitting and predicting completed\n",
      "[12:22:58] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_PB\u001b[0m ...\n",
      "[12:22:58] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_PB\u001b[0m (orig) =====\n",
      "[12:22:58] Stdout logging level is INFO.\n",
      "[12:22:58] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[12:22:58] Iter 0; Sample 0, rmse = 9.208333460906442; \n",
      "[12:22:58] Iter 100; Sample 0, rmse = 2.106452535099679; \n",
      "[12:22:59] Iter 200; Sample 0, rmse = 1.199029630200451; \n",
      "[12:22:59] Iter 300; Sample 0, rmse = 1.0167299819644149; \n",
      "[12:23:00] Iter 400; Sample 0, rmse = 0.9884317422907726; \n",
      "[12:23:00] Iter 500; Sample 0, rmse = 0.9606260892838021; \n",
      "[12:23:01] Iter 600; Sample 0, rmse = 0.9335382054185928; \n",
      "[12:23:01] Iter 700; Sample 0, rmse = 0.9168071502991689; \n",
      "[12:23:02] Iter 800; Sample 0, rmse = 0.9012891852839094; \n",
      "[12:23:02] Iter 900; Sample 0, rmse = 0.8881828117644683; \n",
      "[12:23:02] Iter 1000; Sample 0, rmse = 0.8789869435366705; \n",
      "[12:23:03] Iter 1100; Sample 0, rmse = 0.8683743192248639; \n",
      "[12:23:03] Iter 1200; Sample 0, rmse = 0.8604242862970118; \n",
      "[12:23:04] Iter 1300; Sample 0, rmse = 0.8544355142551223; \n",
      "[12:23:04] Iter 1400; Sample 0, rmse = 0.8394762024435501; \n",
      "[12:23:05] Iter 1500; Sample 0, rmse = 0.831207612730374; \n",
      "[12:23:06] Iter 1600; Sample 0, rmse = 0.8212636863855876; \n",
      "[12:23:06] Iter 1700; Sample 0, rmse = 0.8183456555347811; \n",
      "[12:23:06] Iter 1800; Sample 0, rmse = 0.8151138831150305; \n",
      "[12:23:07] Iter 1900; Sample 0, rmse = 0.8102056738247619; \n",
      "[12:23:07] Iter 2000; Sample 0, rmse = 0.8070333307386427; \n",
      "[12:23:08] Iter 2100; Sample 0, rmse = 0.8034064214046762; \n",
      "[12:23:08] Iter 2200; Sample 0, rmse = 0.8009829157152791; \n",
      "[12:23:09] Iter 2300; Sample 0, rmse = 0.797776575579673; \n",
      "[12:23:09] Iter 2400; Sample 0, rmse = 0.7942915016330309; \n",
      "[12:23:10] Iter 2500; Sample 0, rmse = 0.7913197224958369; \n",
      "[12:23:10] Iter 2600; Sample 0, rmse = 0.7849609515859081; \n",
      "[12:23:11] Iter 2700; Sample 0, rmse = 0.7815406570421702; \n",
      "[12:23:11] Iter 2800; Sample 0, rmse = 0.7801056650168002; \n",
      "[12:23:12] Iter 2900; Sample 0, rmse = 0.7787836637390885; \n",
      "[12:23:12] Iter 2999; Sample 0, rmse = 0.7777473737297125; \n",
      "[12:23:13] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_PB\u001b[0m (orig) =====\n",
      "[12:23:13] Stdout logging level is INFO.\n",
      "[12:23:13] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[12:23:13] Iter 0; Sample 0, rmse = 9.95117703350966; \n",
      "[12:23:14] Iter 100; Sample 0, rmse = 2.422865571761729; \n",
      "[12:23:14] Iter 200; Sample 0, rmse = 1.3913492596630823; \n",
      "[12:23:15] Iter 300; Sample 0, rmse = 1.1984187013621697; \n",
      "[12:23:15] Iter 400; Sample 0, rmse = 1.1242555152522096; \n",
      "[12:23:16] Iter 500; Sample 0, rmse = 1.0554125648523394; \n",
      "[12:23:16] Iter 600; Sample 0, rmse = 1.0003937377035008; \n",
      "[12:23:17] Iter 700; Sample 0, rmse = 0.9650503240953876; \n",
      "[12:23:17] Iter 800; Sample 0, rmse = 0.9499169738432703; \n",
      "[12:23:18] Iter 900; Sample 0, rmse = 0.9325572661115472; \n",
      "[12:23:18] Iter 1000; Sample 0, rmse = 0.9216610567314837; \n",
      "[12:23:19] Iter 1100; Sample 0, rmse = 0.9093061603898879; \n",
      "[12:23:19] Iter 1200; Sample 0, rmse = 0.8969771651473449; \n",
      "[12:23:20] Iter 1300; Sample 0, rmse = 0.8883902366845442; \n",
      "[12:23:20] Iter 1400; Sample 0, rmse = 0.8806256502957546; \n",
      "[12:23:21] Iter 1500; Sample 0, rmse = 0.8717222785899503; \n",
      "[12:23:21] Iter 1600; Sample 0, rmse = 0.8647491994371881; \n",
      "[12:23:22] Iter 1700; Sample 0, rmse = 0.8565025375375915; \n",
      "[12:23:22] Iter 1800; Sample 0, rmse = 0.8510102578958321; \n",
      "[12:23:23] Iter 1900; Sample 0, rmse = 0.8435730452644751; \n",
      "[12:23:23] Iter 2000; Sample 0, rmse = 0.8373878011615735; \n",
      "[12:23:24] Iter 2100; Sample 0, rmse = 0.8323901122058132; \n",
      "[12:23:24] Iter 2200; Sample 0, rmse = 0.8314389805435611; \n",
      "[12:23:24] Iter 2300; Sample 0, rmse = 0.8290845117961857; \n",
      "[12:23:25] Iter 2400; Sample 0, rmse = 0.8250401543147124; \n",
      "[12:23:25] Iter 2500; Sample 0, rmse = 0.819550405292198; \n",
      "[12:23:26] Iter 2600; Sample 0, rmse = 0.8171624771138989; \n",
      "[12:23:26] Iter 2700; Sample 0, rmse = 0.8147523447699736; \n",
      "[12:23:27] Iter 2800; Sample 0, rmse = 0.8096725079769479; \n",
      "[12:23:27] Iter 2900; Sample 0, rmse = 0.8082278567611937; \n",
      "[12:23:27] Iter 2999; Sample 0, rmse = 0.8048781180998895; \n",
      "[12:23:29] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_PB\u001b[0m (orig) =====\n",
      "[12:23:29] Stdout logging level is INFO.\n",
      "[12:23:29] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[12:23:29] Iter 0; Sample 0, rmse = 9.817650854107555; \n",
      "[12:23:29] Iter 100; Sample 0, rmse = 2.459079393159053; \n",
      "[12:23:30] Iter 200; Sample 0, rmse = 1.3811401639547942; \n",
      "[12:23:30] Iter 300; Sample 0, rmse = 1.1168259343719593; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:23:31] Iter 400; Sample 0, rmse = 1.0101994878343423; \n",
      "[12:23:31] Iter 500; Sample 0, rmse = 0.9501870156896989; \n",
      "[12:23:32] Iter 600; Sample 0, rmse = 0.92272069862858; \n",
      "[12:23:32] Iter 700; Sample 0, rmse = 0.9039473099923753; \n",
      "[12:23:32] Iter 800; Sample 0, rmse = 0.8730175083004397; \n",
      "[12:23:33] Iter 900; Sample 0, rmse = 0.8635463115830538; \n",
      "[12:23:33] Iter 1000; Sample 0, rmse = 0.8570847882229982; \n",
      "[12:23:34] Iter 1100; Sample 0, rmse = 0.848652953962316; \n",
      "[12:23:34] Iter 1200; Sample 0, rmse = 0.8404001449096732; \n",
      "[12:23:35] Iter 1300; Sample 0, rmse = 0.8311950957602734; \n",
      "[12:23:35] Iter 1400; Sample 0, rmse = 0.8283914248230217; \n",
      "[12:23:35] Iter 1500; Sample 0, rmse = 0.8257151487212716; \n",
      "[12:23:36] Iter 1600; Sample 0, rmse = 0.8239826721338911; \n",
      "[12:23:36] Iter 1700; Sample 0, rmse = 0.818299408314596; \n",
      "[12:23:37] Iter 1800; Sample 0, rmse = 0.8134062752966031; \n",
      "[12:23:37] Iter 1900; Sample 0, rmse = 0.8097145850032977; \n",
      "[12:23:37] Iter 2000; Sample 0, rmse = 0.8065979953564246; \n",
      "[12:23:38] Iter 2100; Sample 0, rmse = 0.8050417884901027; \n",
      "[12:23:38] Iter 2200; Sample 0, rmse = 0.798723147159041; \n",
      "[12:23:39] Iter 2300; Sample 0, rmse = 0.7963432294256199; \n",
      "[12:23:39] Iter 2400; Sample 0, rmse = 0.7923787416783395; \n",
      "[12:23:40] Iter 2500; Sample 0, rmse = 0.7901914529753696; \n",
      "[12:23:40] Iter 2600; Sample 0, rmse = 0.7802455298481263; \n",
      "[12:23:41] Iter 2700; Sample 0, rmse = 0.7783608536425972; \n",
      "[12:23:41] Iter 2800; Sample 0, rmse = 0.774236932345998; \n",
      "[12:23:41] Iter 2900; Sample 0, rmse = 0.7708657441093594; \n",
      "[12:23:42] Iter 2999; Sample 0, rmse = 0.7693929468477311; \n",
      "[12:23:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_PB\u001b[0m finished. score = \u001b[1m-0.5008425984779994\u001b[0m\n",
      "[12:23:43] \u001b[1mLvl_0_Pipe_1_Mod_1_PB\u001b[0m fitting and predicting completed\n",
      "[12:23:43] Time left 3517.51 secs\n",
      "\n",
      "[12:23:43] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[12:23:43] Blending: Optimization starts with equal weights and score -0.8966289962083103\n",
      "[12:23:43] Blending, iter 0: score = -0.497440597464641, weights = [0.         0.23952763 0.76047236]\n",
      "[12:23:44] Blending, iter 1: score = -0.497440597464641, weights = [0.         0.23952763 0.76047236]\n",
      "[12:23:44] No score update. Terminated\n",
      "[12:23:44] \u001b[1mAutoml preset training completed in 82.67 seconds\u001b[0m\n",
      "\n",
      "[12:23:44] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.23953 * (3 averaged models Lvl_0_Pipe_1_Mod_0_XGB) +\n",
      "\t 0.76047 * (3 averaged models Lvl_0_Pipe_1_Mod_1_PB) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_pred_gpu = automl_gpu.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f31b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d53856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_inf = automl_gpu.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c7558ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi:reg isn`t supported in lgb\n",
      "[12:23:59] CatBoost supports only MultiRMSE metric and loss for multi:reg task.\n",
      "multi:reg isn`t supported in lgb\n",
      "[12:23:59] CatBoost supports only MultiRMSE metric and loss for multi:reg task.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e435aa704120464d877419e665741652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi:reg isn`t supported in lgb\n",
      "[12:24:00] CatBoost supports only MultiRMSE metric and loss for multi:reg task.\n",
      "multi:reg isn`t supported in lgb\n",
      "[12:24:01] CatBoost supports only MultiRMSE metric and loss for multi:reg task.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b304fc19cf6e4a33bd6ba9ed0cb56037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2979 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69896ab9dfb43a18fdceea1368121e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2996 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320278963dfd4ddfbbd21eb403f7278d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2996 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi:reg isn`t supported in lgb\n",
      "[12:24:05] CatBoost supports only MultiRMSE metric and loss for multi:reg task.\n"
     ]
    }
   ],
   "source": [
    "automl_gpu.to_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22280bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "608ac415",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_inf = automl_gpu.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3b98e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/comm/ucx.py:61: UserWarning: A CUDA context for device 0 already exists on process ID 9363. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n",
      "  warnings.warn(\n",
      "2023-01-14 12:25:52,177 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2023-01-14 12:25:52,178 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dashboard: http://127.0.0.1:8787/status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ucx://127.0.0.1:52305': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import cudf\n",
    "\n",
    "cluster = LocalCUDACluster(rmm_managed_memory=True, CUDA_VISIBLE_DEVICES=\"0\",\n",
    "                               protocol=\"ucx\", enable_nvlink=True,\n",
    "                               memory_limit=\"8GB\")\n",
    "print(\"dashboard:\", cluster.dashboard_link)\n",
    "client = Client(cluster)\n",
    "client.run(cudf.set_allocator, \"managed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf8c7fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi:reg isn`t supported in lgb\n",
      "[12:25:54] CatBoost supports only MultiRMSE metric and loss for multi:reg task.\n"
     ]
    }
   ],
   "source": [
    "task = Task('multi:reg', loss = 'mse', device='mgpu')\n",
    "\n",
    "automl_mgpu = TabularAutoMLGPU(\n",
    "    task = task, \n",
    "    timeout = 3600,\n",
    "    cpu_limit = 1,\n",
    "    reader_params = {'n_jobs': 1, 'cv': 3, 'random_state': 42, 'npartitions': 2},\n",
    "    general_params = {'use_algos': [['xgb', 'linear_l2']]},\n",
    "    client = client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ff1a5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:25:56] Stdout logging level is INFO2.\n",
      "[12:25:56] Task: multi:reg\n",
      "\n",
      "[12:25:56] Start automl preset with listed constraints:\n",
      "[12:25:56] - time: 3600.00 seconds\n",
      "[12:25:56] - CPU: 1 cores\n",
      "[12:25:56] - memory: 16 GB\n",
      "\n",
      "[12:25:56] Train data shape: (768, 10)\n",
      "[12:25:56] Feats was rejected during automatic roles guess: []\n",
      "[12:25:56] Layer \u001b[1m1\u001b[0m train process start. Time left 3599.71 secs\n",
      "[12:25:56] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[12:25:56] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[12:25:57] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[12:25:58] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m (orig) =====\n",
      "[12:25:58] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-2.1765454036990803\u001b[0m\n",
      "[12:25:58] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[12:25:58] Time left 3597.69 secs\n",
      "\n",
      "[12:25:58] Stdout logging level is INFO.\n",
      "[12:25:58] GDBT train starts. Max iter 3000, early stopping rounds 200\n",
      "[12:25:58] Iter 0; Sample 0, rmse = 9.208333468351562; \n",
      "[12:25:59] Iter 100; Sample 0, rmse = 2.1064522840747273; \n",
      "[12:25:59] Iter 200; Sample 0, rmse = 1.1998703660256727; \n",
      "[12:25:59] Iter 300; Sample 0, rmse = 1.0178207598337385; \n",
      "[12:26:00] Iter 400; Sample 0, rmse = 0.9894385629155987; \n",
      "[12:26:00] Iter 500; Sample 0, rmse = 0.9616133824458649; \n",
      "[12:26:01] Iter 600; Sample 0, rmse = 0.9344896913621897; \n",
      "[12:26:01] Iter 700; Sample 0, rmse = 0.917709558168447; \n",
      "[12:26:01] Iter 800; Sample 0, rmse = 0.9021610766268561; \n",
      "[12:26:02] Iter 900; Sample 0, rmse = 0.8890581074678103; \n",
      "[12:26:02] Iter 1000; Sample 0, rmse = 0.879830872673854; \n",
      "[12:26:03] Iter 1100; Sample 0, rmse = 0.8691648678139096; \n",
      "[12:26:03] Iter 1200; Sample 0, rmse = 0.8611624717704902; \n",
      "[12:26:03] Iter 1300; Sample 0, rmse = 0.8551419109141546; \n",
      "[12:26:04] Iter 1400; Sample 0, rmse = 0.8401941123098314; \n",
      "[12:26:04] Iter 1500; Sample 0, rmse = 0.8319147377326656; \n",
      "[12:26:05] Iter 1600; Sample 0, rmse = 0.821964718951678; \n",
      "[12:26:05] Iter 1700; Sample 0, rmse = 0.8190350455468698; \n",
      "[12:26:05] Iter 1800; Sample 0, rmse = 0.8157987158389377; \n",
      "[12:26:06] Iter 1900; Sample 0, rmse = 0.8108893784412656; \n",
      "[12:26:06] Iter 2000; Sample 0, rmse = 0.8077487267524529; \n",
      "[12:26:07] Iter 2100; Sample 0, rmse = 0.804144481262316; \n",
      "[12:26:07] Iter 2200; Sample 0, rmse = 0.8017315818150013; \n",
      "[12:26:07] Iter 2300; Sample 0, rmse = 0.7985611951322495; \n",
      "[12:26:08] Iter 2400; Sample 0, rmse = 0.7952189346054622; \n",
      "[12:26:08] Iter 2500; Sample 0, rmse = 0.7941161218038303; \n",
      "[12:26:09] Iter 2600; Sample 0, rmse = 0.7895779414006991; \n",
      "[12:26:09] Iter 2700; Sample 0, rmse = 0.784758892906491; \n",
      "[12:26:09] Iter 2800; Sample 0, rmse = 0.7814356754834664; \n",
      "[12:26:10] Iter 2900; Sample 0, rmse = 0.7794475749609904; \n",
      "[12:26:10] Iter 2999; Sample 0, rmse = 0.7778240434276014; \n",
      "[12:26:12] \u001b[1mSelector_PB\u001b[0m fitting and predicting completed\n",
      "[12:26:12] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m ...\n",
      "[12:26:12] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[12:26:21] task [xgboost.dask-0]:ucx://127.0.0.1:52305 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:26:26] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[12:26:26] task [xgboost.dask-0]:ucx://127.0.0.1:52305 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:26:31] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m (orig) =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/xgboost/dask.py:884: RuntimeWarning: coroutine 'Client._wait_for_workers' was never awaited\n",
      "  client.wait_for_workers(n_workers)\n",
      "/home/rishat/miniconda3/envs/rapids-22.10/lib/python3.9/site-packages/distributed/worker_state_machine.py:3649: FutureWarning: The `Worker.nthreads` attribute has been moved to `Worker.state.nthreads`\n",
      "  warnings.warn(\n",
      "[12:26:32] task [xgboost.dask-0]:ucx://127.0.0.1:52305 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:26:36] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m finished. score = \u001b[1m-0.5334486607213815\u001b[0m\n",
      "[12:26:36] \u001b[1mLvl_0_Pipe_1_Mod_0_XGB\u001b[0m fitting and predicting completed\n",
      "[12:26:36] Time left 3559.81 secs\n",
      "\n",
      "[12:26:36] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[12:26:36] Blending: Optimization starts with equal weights and score -1.204309390621881\n",
      "[12:26:36] Blending, iter 0: score = -0.5334486607213815, weights = [0. 1.]\n",
      "[12:26:36] Blending, iter 1: score = -0.5334486607213815, weights = [0. 1.]\n",
      "[12:26:36] No score update. Terminated\n",
      "[12:26:36] \u001b[1mAutoml preset training completed in 40.28 seconds\u001b[0m\n",
      "\n",
      "[12:26:36] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (3 averaged models Lvl_0_Pipe_1_Mod_0_XGB) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_pred_mgpu = automl_mgpu.fit_predict(data, roles = roles, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc74a00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.523565 21.312319 21.028816 ... 16.399435 16.244144 16.245834]\n",
      " [16.196108 16.262726 15.902071 ... 16.34151  16.377163 16.371582]]\n",
      "\n",
      "[[22.523571 21.312319 21.028824 ... 16.399435 16.244144 16.245857]\n",
      " [16.196121 16.262749 15.902094 ... 16.341505 16.377167 16.371584]]\n",
      "\n",
      "[[23.492664 22.157509 20.964127 ... 16.419237 16.120636 16.357498]\n",
      " [17.01507  16.901182 15.929466 ... 16.257198 16.373657 16.361753]]\n",
      "\n",
      "[[22.325417 21.209105 21.430384 ... 16.482996 15.88877  16.432215]\n",
      " [15.770237 15.915673 15.78574  ... 16.53469  16.339546 16.176693]]\n",
      "\n",
      "[[22.363066 21.329357 20.67113  ... 16.549248 16.567663 16.55196 ]\n",
      " [15.921541 16.009209 15.802179 ... 16.367476 16.34037  16.462301]]\n"
     ]
    }
   ],
   "source": [
    "print(cpu_inf.data.T)\n",
    "print()\n",
    "print(gpu_inf.data.T)\n",
    "print()\n",
    "print(oof_pred_gpu.data.T)\n",
    "print()\n",
    "print(oof_pred.data.T)\n",
    "print()\n",
    "print(oof_pred_mgpu.data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61f0ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d946297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f74a36d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-22.10",
   "language": "python",
   "name": "rapids-22.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
