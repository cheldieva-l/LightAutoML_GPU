{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this tutorial you will learn how to:\n",
    "* run LightAutoML GPU version training on tabular data\n",
    "* obtain feature importances and reports\n",
    "* configure resource usage in LightAutoML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.066681,
     "end_time": "2021-06-22T20:10:53.090975",
     "exception": false,
     "start_time": "2021-06-22T20:10:53.024294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 0.1. Import libraries\n",
    "\n",
    "Here we will import the libraries we use in this kernel:\n",
    "- Standard python libraries for timing, working with OS etc.\n",
    "- Essential python DS libraries like numpy, pandas, scikit-learn and torch (the last we will use in the next cell)\n",
    "- LightAutoML modules: presets for AutoML, task and report generation module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:10:53.233356Z",
     "iopub.status.busy": "2021-06-22T20:10:53.232675Z",
     "iopub.status.idle": "2021-06-22T20:11:01.486841Z",
     "shell.execute_reply": "2021-06-22T20:11:01.487566Z",
     "shell.execute_reply.started": "2021-06-22T19:06:43.597648Z"
    },
    "papermill": {
     "duration": 8.32949,
     "end_time": "2021-06-22T20:11:01.487788",
     "exception": false,
     "start_time": "2021-06-22T20:10:53.158298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level \"INFO2: 17\" already defined, skipping...\n",
      "Level \"INFO3: 13\" already defined, skipping...\n",
      "'pdf' extra dependecy package 'weasyprint' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'pdf' extra dependecy package 'weasyprint' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n"
     ]
    }
   ],
   "source": [
    "# Standard python libraries\n",
    "import os\n",
    "# Optional: set the device to run\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\"\n",
    "\n",
    "import time\n",
    "\n",
    "# Essential DS libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# LightAutoML presets, task and report generation\n",
    "from lightautoml_gpu.automl.presets.gpu.tabular_gpu_presets import TabularAutoMLGPU\n",
    "from lightautoml_gpu.tasks import Task\n",
    "from lightautoml_gpu.report.gpu import ReportDeco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.064234,
     "end_time": "2021-06-22T20:11:01.619010",
     "exception": false,
     "start_time": "2021-06-22T20:11:01.554776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 0.2. Constants\n",
    "\n",
    "Here we setup the constants to use in the kernel:\n",
    "- `N_THREADS` - number of vCPUs for LightAutoML model creation\n",
    "- `N_FOLDS` - number of folds in LightAutoML inner CV\n",
    "- `RANDOM_STATE` - random seed for better reproducibility\n",
    "- `TEST_SIZE` - houldout data part size \n",
    "- `TIMEOUT` - limit in seconds for model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:11:01.758476Z",
     "iopub.status.busy": "2021-06-22T20:11:01.757403Z",
     "iopub.status.idle": "2021-06-22T20:11:01.760870Z",
     "shell.execute_reply": "2021-06-22T20:11:01.760168Z",
     "shell.execute_reply.started": "2021-06-22T19:06:51.523697Z"
    },
    "papermill": {
     "duration": 0.077787,
     "end_time": "2021-06-22T20:11:01.761030",
     "exception": false,
     "start_time": "2021-06-22T20:11:01.683243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "TIMEOUT = 300\n",
    "N_THREADS = 4\n",
    "N_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = './data/'\n",
    "DATASET_NAMES = ['higgs.csv', 'Fashion-MNIST.csv']\n",
    "DATASET_FULLNAME = [os.path.join(DATASET_DIR, name) for name in DATASET_NAMES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.072033,
     "end_time": "2021-06-22T20:11:02.238196",
     "exception": false,
     "start_time": "2021-06-22T20:11:02.166163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 0.3. Data loading\n",
    "Let's check the data we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:11:02.386568Z",
     "iopub.status.busy": "2021-06-22T20:11:02.385526Z",
     "iopub.status.idle": "2021-06-22T20:11:15.017602Z",
     "shell.execute_reply": "2021-06-22T20:11:15.018159Z",
     "shell.execute_reply.started": "2021-06-22T19:06:51.545269Z"
    },
    "papermill": {
     "duration": 12.710747,
     "end_time": "2021-06-22T20:11:15.018360",
     "exception": false,
     "start_time": "2021-06-22T20:11:02.307613",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14198/3578130192.py:1: DtypeWarning: Columns (20,21,22,23,24,25,26,27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('./data/higgs.csv')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/higgs.csv')\n",
    "data.head()\n",
    "\n",
    "data_info_ = {\n",
    "                'path': 'openml/higgs.csv',\n",
    "                'target': 'class',\n",
    "                'task_type': 'binary',\n",
    "                'read_csv_params': {'na_values': '?'}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for col in data.columns:\n",
    "    if data[col].isin(['?']).any():\n",
    "        data[col] = data[col].replace('?', np.nan).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.065323,
     "end_time": "2021-06-22T20:11:21.676311",
     "exception": false,
     "start_time": "2021-06-22T20:11:21.610988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 0.4 Data splitting for train-holdout\n",
    "As we have only one file with target values, we can split it into 80%-20% for holdout usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:11:21.814622Z",
     "iopub.status.busy": "2021-06-22T20:11:21.813630Z",
     "iopub.status.idle": "2021-06-22T20:11:22.537639Z",
     "shell.execute_reply": "2021-06-22T20:11:22.537037Z",
     "shell.execute_reply.started": "2021-06-22T19:07:07.916060Z"
    },
    "papermill": {
     "duration": 0.793619,
     "end_time": "2021-06-22T20:11:22.537798",
     "exception": false,
     "start_time": "2021-06-22T20:11:21.744179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitted. Parts sizes: tr_data = (78440, 29), te_data = (19610, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>lepton_pT</th>\n",
       "      <th>lepton_eta</th>\n",
       "      <th>lepton_phi</th>\n",
       "      <th>missing_energy_magnitude</th>\n",
       "      <th>missing_energy_phi</th>\n",
       "      <th>jet1pt</th>\n",
       "      <th>jet1eta</th>\n",
       "      <th>jet1phi</th>\n",
       "      <th>jet1b-tag</th>\n",
       "      <th>...</th>\n",
       "      <th>jet4eta</th>\n",
       "      <th>jet4phi</th>\n",
       "      <th>jet4b-tag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.033086</td>\n",
       "      <td>-0.027325</td>\n",
       "      <td>0.556388</td>\n",
       "      <td>0.716491</td>\n",
       "      <td>-1.623269</td>\n",
       "      <td>1.044414</td>\n",
       "      <td>-0.149550</td>\n",
       "      <td>-1.633134</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891493</td>\n",
       "      <td>0.128023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.221998</td>\n",
       "      <td>1.333303</td>\n",
       "      <td>1.101426</td>\n",
       "      <td>0.886849</td>\n",
       "      <td>1.525385</td>\n",
       "      <td>1.250846</td>\n",
       "      <td>1.042270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.149442</td>\n",
       "      <td>0.240516</td>\n",
       "      <td>-1.208732</td>\n",
       "      <td>0.803575</td>\n",
       "      <td>1.224382</td>\n",
       "      <td>0.504847</td>\n",
       "      <td>0.587181</td>\n",
       "      <td>0.661531</td>\n",
       "      <td>1.086538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587601</td>\n",
       "      <td>-0.081836</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.161402</td>\n",
       "      <td>1.038688</td>\n",
       "      <td>1.479556</td>\n",
       "      <td>1.069424</td>\n",
       "      <td>0.603161</td>\n",
       "      <td>0.783799</td>\n",
       "      <td>0.821149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.669081</td>\n",
       "      <td>0.802496</td>\n",
       "      <td>1.645025</td>\n",
       "      <td>1.346262</td>\n",
       "      <td>-1.145997</td>\n",
       "      <td>0.690627</td>\n",
       "      <td>-1.126907</td>\n",
       "      <td>0.855008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040348</td>\n",
       "      <td>-1.595084</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.037140</td>\n",
       "      <td>0.983492</td>\n",
       "      <td>0.995939</td>\n",
       "      <td>0.926378</td>\n",
       "      <td>0.886266</td>\n",
       "      <td>0.912128</td>\n",
       "      <td>0.883060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.444346</td>\n",
       "      <td>-0.500674</td>\n",
       "      <td>-0.364785</td>\n",
       "      <td>0.716306</td>\n",
       "      <td>0.833619</td>\n",
       "      <td>0.939249</td>\n",
       "      <td>-0.048547</td>\n",
       "      <td>-0.799354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.398159</td>\n",
       "      <td>0.857178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.584398</td>\n",
       "      <td>1.213435</td>\n",
       "      <td>0.983564</td>\n",
       "      <td>0.895563</td>\n",
       "      <td>0.841721</td>\n",
       "      <td>1.141312</td>\n",
       "      <td>0.922072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.434464</td>\n",
       "      <td>0.240516</td>\n",
       "      <td>-0.117872</td>\n",
       "      <td>1.407808</td>\n",
       "      <td>1.084599</td>\n",
       "      <td>1.574911</td>\n",
       "      <td>-1.624993</td>\n",
       "      <td>0.106601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089573</td>\n",
       "      <td>-0.513003</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.234359</td>\n",
       "      <td>1.151361</td>\n",
       "      <td>0.988237</td>\n",
       "      <td>0.614409</td>\n",
       "      <td>0.679219</td>\n",
       "      <td>0.704437</td>\n",
       "      <td>0.701936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  lepton_pT  lepton_eta  lepton_phi  missing_energy_magnitude  \\\n",
       "0      1   1.033086   -0.027325    0.556388                  0.716491   \n",
       "1      1   2.149442    0.240516   -1.208732                  0.803575   \n",
       "2      0   0.669081    0.802496    1.645025                  1.346262   \n",
       "3      0   0.444346   -0.500674   -0.364785                  0.716306   \n",
       "4      0   0.434464    0.240516   -0.117872                  1.407808   \n",
       "\n",
       "   missing_energy_phi    jet1pt   jet1eta   jet1phi  jet1b-tag  ...   jet4eta  \\\n",
       "0           -1.623269  1.044414 -0.149550 -1.633134   2.173076  ...  0.891493   \n",
       "1            1.224382  0.504847  0.587181  0.661531   1.086538  ... -0.587601   \n",
       "2           -1.145997  0.690627 -1.126907  0.855008   0.000000  ...  0.040348   \n",
       "3            0.833619  0.939249 -0.048547 -0.799354   0.000000  ... -2.398159   \n",
       "4            1.084599  1.574911 -1.624993  0.106601   0.000000  ... -0.089573   \n",
       "\n",
       "    jet4phi  jet4b-tag      m_jj     m_jjj      m_lv     m_jlv      m_bb  \\\n",
       "0  0.128023   0.000000  1.221998  1.333303  1.101426  0.886849  1.525385   \n",
       "1 -0.081836   3.101961  1.161402  1.038688  1.479556  1.069424  0.603161   \n",
       "2 -1.595084   3.101961  1.037140  0.983492  0.995939  0.926378  0.886266   \n",
       "3  0.857178   0.000000  1.584398  1.213435  0.983564  0.895563  0.841721   \n",
       "4 -0.513003   3.101961  1.234359  1.151361  0.988237  0.614409  0.679219   \n",
       "\n",
       "      m_wbb    m_wwbb  \n",
       "0  1.250846  1.042270  \n",
       "1  0.783799  0.821149  \n",
       "2  0.912128  0.883060  \n",
       "3  1.141312  0.922072  \n",
       "4  0.704437  0.701936  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data, te_data = train_test_split(\n",
    "    data, \n",
    "    test_size=TEST_SIZE, \n",
    "    stratify=data['class'], \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f'Data splitted. Parts sizes: tr_data = {tr_data.shape}, te_data = {te_data.shape}')\n",
    "tr_data = tr_data.reset_index(drop=True)\n",
    "te_data = te_data.reset_index(drop=True)\n",
    "tr_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.071526,
     "end_time": "2021-06-22T20:11:22.853156",
     "exception": false,
     "start_time": "2021-06-22T20:11:22.781630",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Task definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Task type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On the cell below we create Task object - the class to setup what task LightAutoML model should solve with specific loss and metric if necessary (more info can be found [here](https://lightautoml.readthedocs.io/en/latest/generated/lightautoml.tasks.base.Task.html#lightautoml.tasks.base.Task) in our documentation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:11:23.005952Z",
     "iopub.status.busy": "2021-06-22T20:11:23.002234Z",
     "iopub.status.idle": "2021-06-22T20:11:23.009732Z",
     "shell.execute_reply": "2021-06-22T20:11:23.010398Z",
     "shell.execute_reply.started": "2021-06-22T19:07:08.656347Z"
    },
    "papermill": {
     "duration": 0.086442,
     "end_time": "2021-06-22T20:11:23.010643",
     "exception": false,
     "start_time": "2021-06-22T20:11:22.924201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = Task('binary', device='gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.070103,
     "end_time": "2021-06-22T20:11:23.150929",
     "exception": false,
     "start_time": "2021-06-22T20:11:23.080826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.2. Feature roles setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.069372,
     "end_time": "2021-06-22T20:11:23.290153",
     "exception": false,
     "start_time": "2021-06-22T20:11:23.220781",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To solve the task, we need to setup columns roles. The **only role you must setup is target role**, everything else (drop, numeric, categorical, group, weights etc.) is up to user - LightAutoML models have automatic columns typization inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:11:23.434600Z",
     "iopub.status.busy": "2021-06-22T20:11:23.433707Z",
     "iopub.status.idle": "2021-06-22T20:11:23.438088Z",
     "shell.execute_reply": "2021-06-22T20:11:23.438653Z",
     "shell.execute_reply.started": "2021-06-22T19:07:08.673897Z"
    },
    "papermill": {
     "duration": 0.07715,
     "end_time": "2021-06-22T20:11:23.438830",
     "exception": false,
     "start_time": "2021-06-22T20:11:23.361680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "roles = {\n",
    "    'target': 'class',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.074284,
     "end_time": "2021-06-22T20:11:23.582462",
     "exception": false,
     "start_time": "2021-06-22T20:11:23.508178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.3. LightAutoML model creation - TabularAutoML preset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.072649,
     "end_time": "2021-06-22T20:11:23.726154",
     "exception": false,
     "start_time": "2021-06-22T20:11:23.653505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In next the cell we are going to create LightAutoML model with `TabularAutoML` class - preset with default model structure like in the image below:\n",
    "\n",
    "<img src=\"../../imgs/tutorial_blackbox_pipeline.png\" alt=\"TabularAutoML preset pipeline\" style=\"width:85%;\"/>\n",
    "\n",
    "in just several lines. Let's discuss the params we can setup:\n",
    "- `task` - the type of the ML task (the only **must have** parameter)\n",
    "- `timeout` - time limit in seconds for model to train\n",
    "- `cpu_limit` - vCPU count for model to use\n",
    "- `reader_params` - parameter change for Reader object inside preset, which works on the first step of data preparation: automatic feature typization, preliminary almost-constant features, correct CV setup etc. For example, we setup `n_jobs` threads for typization algo, `cv` folds and `random_state` as inside CV seed.\n",
    "\n",
    "**Important note**: `reader_params` key is one of the YAML config keys, which is used inside `TabularAutoML` preset. [More details](https://github.com/sberbank-ai-lab/LightAutoML/blob/master/lightautoml/automl/presets/tabular_config.yml) on its structure with explanation comments can be found on the link attached. Each key from this config can be modified with user settings during preset object initialization. To get more info about different parameters setting (for example, ML algos which can be used in `general_params->use_algos`) please take a look at our [article on TowardsDataScience](https://towardsdatascience.com/lightautoml-preset-usage-tutorial-2cce7da6f936).\n",
    "\n",
    "Moreover, to receive the automatic report for our model we will use `ReportDeco` decorator and work with the decorated version in the same way as we do with usual one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoMLGPU(task=task,    \n",
    "                          reader_params = {'n_jobs': 2, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    "    timeout=TIMEOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. AutoML training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run autoML training use fit_predict method:\n",
    "\n",
    "- `train_data` - Dataset to train.\n",
    "- `roles` - Roles dict.\n",
    "- `verbose` - Controls the verbosity: the higher, the more messages.\n",
    "        <1  : messages are not displayed;\n",
    "        >=1 : the computation process for layers is displayed;\n",
    "        >=2 : the information about folds processing is also displayed;\n",
    "        >=3 : the hyperparameters optimization process is also displayed;\n",
    "        >=4 : the training process for every algorithm is displayed;\n",
    "\n",
    "Note: out-of-fold prediction is calculated during training and returned from the fit_predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:21] Stdout logging level is INFO.\n",
      "[11:24:21] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[11:24:21] Task: binary\n",
      "\n",
      "[11:24:21] Start automl preset with listed constraints:\n",
      "[11:24:21] - time: 300.00 seconds\n",
      "[11:24:21] - CPU: 4 cores\n",
      "[11:24:21] - memory: 16 GB\n",
      "\n",
      "[11:24:21] Train data shape: (78440, 29)\n",
      "[11:24:24] Feats was rejected during automatic roles guess: []\n",
      "[11:24:24] Layer \u001b[1m1\u001b[0m train process start. Time left 296.75 secs\n",
      "[11:24:24] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:24:35] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7598962501666371\u001b[0m\n",
      "[11:24:35] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:24:35] Time left 285.83 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:46] \u001b[1mSelector_CatBoostGPU\u001b[0m fitting and predicting completed\n",
      "[11:24:46] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:08] Time limit exceeded after calculating fold 1\n",
      "[11:25:08] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m finished. score = \u001b[1m0.8082826111646088\u001b[0m\n",
      "[11:25:08] \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m fitting and predicting completed\n",
      "[11:25:08] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_CatBoostGPU\u001b[0m ... Time budget is 1.00 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:18] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_CatBoostGPU\u001b[0m completed\n",
      "[11:25:18] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m ...\n",
      "[11:25:39] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m finished. score = \u001b[1m0.8064250733140045\u001b[0m\n",
      "[11:25:39] \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m fitting and predicting completed\n",
      "[11:25:39] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m ... Time budget is 125.03 secs\n",
      "[11:27:47] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m completed\n",
      "[11:27:47] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m ...\n",
      "[11:28:01] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m finished. score = \u001b[1m0.8077146571412942\u001b[0m\n",
      "[11:28:01] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m fitting and predicting completed\n",
      "[11:28:01] Time left 79.47 secs\n",
      "\n",
      "[11:28:01] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "[11:28:01] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:28:01] Blending: Optimization starts with equal weights and score 0.8054819598058426\n",
      "[11:28:02] Blending, iter 0: score = 0.8091290621055858, weights = [0.         0.3757265  0.22569425 0.39857927]\n",
      "[11:28:02] Blending, iter 1: score = 0.8091318937984079, weights = [0.         0.34661034 0.2433318  0.41005787]\n",
      "[11:28:02] Blending, iter 2: score = 0.8091318937984079, weights = [0.         0.34661034 0.2433318  0.41005787]\n",
      "[11:28:02] No score update. Terminated\n",
      "[11:28:02] \u001b[1mAutoml preset training completed in 221.25 seconds\u001b[0m\n",
      "\n",
      "[11:28:02] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.34661 * (2 averaged models Lvl_0_Pipe_1_Mod_0_CatBoostGPU) +\n",
      "\t 0.24333 * (5 averaged models Lvl_0_Pipe_1_Mod_2_XGB) +\n",
      "\t 0.41006 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_XGB) \n",
      "\n",
      "CPU times: user 4min 23s, sys: 41.4 s, total: 5min 4s\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "oof_pred = automl.fit_predict(tr_data, roles = roles, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.145098,
     "end_time": "2021-06-22T20:34:32.530768",
     "exception": false,
     "start_time": "2021-06-22T20:34:32.385670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Prediction on holdout and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for te_data:\n",
      "array([[0.4404504 ],\n",
      "       [0.38410228],\n",
      "       [0.87378585],\n",
      "       ...,\n",
      "       [0.62457174],\n",
      "       [0.889362  ],\n",
      "       [0.6726755 ]], dtype=float32)\n",
      "Shape = (19610, 1)\n",
      "CPU times: user 296 ms, sys: 58.9 ms, total: 355 ms\n",
      "Wall time: 345 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "te_pred = automl.predict(te_data)\n",
    "print(f'Prediction for te_data:\\n{te_pred}\\nShape = {te_pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score: 0.8091324628763734\n",
      "HOLDOUT score: 0.8118069479675981\n"
     ]
    }
   ],
   "source": [
    "auc_val = roc_auc_score(tr_data[data_info_['target']].values, oof_pred.data[:, 0])\n",
    "print(f'OOF score: {auc_val}')\n",
    "auc_test = roc_auc_score(te_data[data_info_['target']].values, te_pred.data[:, 0])\n",
    "print(f'HOLDOUT score: {auc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can obtain the description of the resulting pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction for new objects (level 0) = \n",
      "\t 0.34661 * (2 averaged models Lvl_0_Pipe_1_Mod_0_CatBoostGPU) +\n",
      "\t 0.24333 * (5 averaged models Lvl_0_Pipe_1_Mod_2_XGB) +\n",
      "\t 0.41006 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_XGB) \n"
     ]
    }
   ],
   "source": [
    "print(automl.create_model_str_desc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also for this purposes LightAutoML have ReportDeco, use it to build reports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-06-22T20:11:23.898451Z",
     "iopub.status.busy": "2021-06-22T20:11:23.882755Z",
     "iopub.status.idle": "2021-06-22T20:28:33.962394Z",
     "shell.execute_reply": "2021-06-22T20:28:33.962995Z",
     "shell.execute_reply.started": "2021-06-22T19:07:31.468238Z"
    },
    "papermill": {
     "duration": 1030.159528,
     "end_time": "2021-06-22T20:28:33.963476",
     "exception": false,
     "start_time": "2021-06-22T20:11:23.803948",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "RD = ReportDeco(output_path = 'tabularAutoML_model_report')\n",
    "\n",
    "automl_rd = RD(\n",
    "    TabularAutoMLGPU(\n",
    "        task = task, \n",
    "        timeout = TIMEOUT,\n",
    "        reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:02] Stdout logging level is INFO.\n",
      "[11:28:02] Task: binary\n",
      "\n",
      "[11:28:02] Start automl preset with listed constraints:\n",
      "[11:28:02] - time: 300.00 seconds\n",
      "[11:28:02] - CPU: 4 cores\n",
      "[11:28:02] - memory: 16 GB\n",
      "\n",
      "[11:28:02] Train data shape: (78440, 29)\n",
      "[11:28:06] Feats was rejected during automatic roles guess: []\n",
      "[11:28:06] Layer \u001b[1m1\u001b[0m train process start. Time left 296.50 secs\n",
      "[11:28:06] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:28:16] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7598962501666371\u001b[0m\n",
      "[11:28:16] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:28:16] Time left 286.79 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:27] \u001b[1mSelector_CatBoostGPU\u001b[0m fitting and predicting completed\n",
      "[11:28:27] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:50] Time limit exceeded after calculating fold 1\n",
      "[11:28:50] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m finished. score = \u001b[1m0.8084279148400775\u001b[0m\n",
      "[11:28:50] \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m fitting and predicting completed\n",
      "[11:28:50] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_CatBoostGPU\u001b[0m ... Time budget is 1.00 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:00] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_CatBoostGPU\u001b[0m completed\n",
      "[11:29:00] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m ...\n",
      "[11:29:21] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m finished. score = \u001b[1m0.8064250733140045\u001b[0m\n",
      "[11:29:21] \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m fitting and predicting completed\n",
      "[11:29:21] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m ... Time budget is 124.23 secs\n",
      "[11:31:27] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m completed\n",
      "[11:31:27] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m ...\n",
      "[11:31:42] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m finished. score = \u001b[1m0.8077146571412942\u001b[0m\n",
      "[11:31:42] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m fitting and predicting completed\n",
      "[11:31:42] Time left 80.84 secs\n",
      "\n",
      "[11:31:42] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "[11:31:42] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:31:42] Blending: Optimization starts with equal weights and score 0.805490614356587\n",
      "[11:31:42] Blending, iter 0: score = 0.8091536632318934, weights = [0.         0.38310683 0.22416577 0.39272746]\n",
      "[11:31:43] Blending, iter 1: score = 0.8091569120311441, weights = [0.         0.35009238 0.24861825 0.4012894 ]\n",
      "[11:31:43] Blending, iter 2: score = 0.8091568709401277, weights = [0.         0.35009238 0.24861823 0.40128937]\n",
      "[11:31:44] Blending, iter 3: score = 0.8091568709401277, weights = [0.         0.35009238 0.24861823 0.40128937]\n",
      "[11:31:44] No score update. Terminated\n",
      "[11:31:44] \u001b[1mAutoml preset training completed in 221.06 seconds\u001b[0m\n",
      "\n",
      "[11:31:44] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.35009 * (2 averaged models Lvl_0_Pipe_1_Mod_0_CatBoostGPU) +\n",
      "\t 0.24862 * (5 averaged models Lvl_0_Pipe_1_Mod_2_XGB) +\n",
      "\t 0.40129 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_XGB) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/GLAMA/LightAutoML_GPU/lightautoml_gpu/report/gpu/report_deco_gpu.py:141: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(\n",
      "/home/anton/GLAMA/LightAutoML_GPU/lightautoml_gpu/report/gpu/report_deco_gpu.py:148: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 30s, sys: 45.2 s, total: 5min 15s\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oof_pred = automl_rd.fit_predict(tr_data, roles = roles, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the report is available in tabularAutoML_model_report folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_importance.png\t\t       test_roc_curve_1.png\r\n",
      "lama_interactive_report.html\t       valid_distribution_of_logits.png\r\n",
      "test_distribution_of_logits_1.png      valid_pie_f1_metric.png\r\n",
      "test_pie_f1_metric_1.png\t       valid_pr_curve.png\r\n",
      "test_pr_curve_1.png\t\t       valid_preds_distribution_by_bins.png\r\n",
      "test_preds_distribution_by_bins_1.png  valid_roc_curve.png\r\n"
     ]
    }
   ],
   "source": [
    "!ls tabularAutoML_model_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:34:32.909392Z",
     "iopub.status.busy": "2021-06-22T20:34:32.850821Z",
     "iopub.status.idle": "2021-06-22T20:34:55.170012Z",
     "shell.execute_reply": "2021-06-22T20:34:55.170702Z",
     "shell.execute_reply.started": "2021-06-22T19:36:39.413930Z"
    },
    "papermill": {
     "duration": 22.483603,
     "end_time": "2021-06-22T20:34:55.170931",
     "exception": false,
     "start_time": "2021-06-22T20:34:32.687328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/GLAMA/LightAutoML_GPU/lightautoml_gpu/report/gpu/report_deco_gpu.py:141: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(\n",
      "/home/anton/GLAMA/LightAutoML_GPU/lightautoml_gpu/report/gpu/report_deco_gpu.py:148: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for te_data:\n",
      "array([[0.43421286],\n",
      "       [0.38365534],\n",
      "       [0.87341905],\n",
      "       ...,\n",
      "       [0.6125117 ],\n",
      "       [0.89171875],\n",
      "       [0.674551  ]], dtype=float32)\n",
      "Shape = (19610, 1)\n",
      "CPU times: user 5.63 s, sys: 3.64 s, total: 9.27 s\n",
      "Wall time: 2.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "te_pred = automl_rd.predict(te_data)\n",
    "print(f'Prediction for te_data:\\n{te_pred}\\nShape = {te_pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:34:55.470121Z",
     "iopub.status.busy": "2021-06-22T20:34:55.468938Z",
     "iopub.status.idle": "2021-06-22T20:34:55.629520Z",
     "shell.execute_reply": "2021-06-22T20:34:55.630295Z",
     "shell.execute_reply.started": "2021-06-22T19:37:24.055023Z"
    },
    "papermill": {
     "duration": 0.310292,
     "end_time": "2021-06-22T20:34:55.630539",
     "exception": false,
     "start_time": "2021-06-22T20:34:55.320247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score: 0.8091570483489605\n",
      "HOLDOUT score: 0.8117409261782683\n"
     ]
    }
   ],
   "source": [
    "auc_val = roc_auc_score(tr_data[data_info_['target']].values, oof_pred.data[:, 0])\n",
    "print(f'OOF score: {auc_val}')\n",
    "auc_test = roc_auc_score(te_data[data_info_['target']].values, te_pred.data[:, 0])\n",
    "print(f'HOLDOUT score: {auc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-GPU results\n",
    "\n",
    "Here is an example of how to run Multi-GPU configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``cluster`` is an object that connects all GPUS and handles their communication. You should pass indices of GPUs that you want to use for LAMA training through parameter `CUDA_VISIBLE_DEVICES`.\n",
    "\n",
    "Also, other specifications are passed to `cluster` but you can leave these parameters unchanged, as shown in the example.\n",
    "\n",
    "After that, an instance of `client` is created and it should be passed to `automl` object if you want to run multi-GPU training.\n",
    "\n",
    "Finally you can run training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/.conda/envs/rapids-23.02/lib/python3.8/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 42697 instead\n",
      "  warnings.warn(\n",
      "2023-08-10 11:31:52,073 - distributed.comm.ucx - WARNING - A CUDA context for device 0 (b'GPU-b0462d46-9248-fcb0-0ee8-63a5eda3462b') already exists on process ID 14198. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1691667112.088057] [automlgpu:14198:0]          parser.c:1908 UCX  WARN  unused env variable: UCX_MEMTYPE_CACHE (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 11:31:54,211 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ak6iwjl4', purging\n",
      "2023-08-10 11:31:54,211 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2023-08-10 11:31:54,211 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2023-08-10 11:31:54,351 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2023-08-10 11:31:54,351 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ucx://127.0.0.1:36181': None, 'ucx://127.0.0.1:47065': None}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCUDACluster(rmm_managed_memory=True, CUDA_VISIBLE_DEVICES=\"0, 1\",\n",
    "                               protocol=\"ucx\", enable_nvlink=True,\n",
    "                               memory_limit=\"30GB\")\n",
    "\n",
    "client = Client(cluster)\n",
    "client.run(cudf.set_allocator, \"managed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:35:42] Stdout logging level is INFO.\n",
      "[11:35:42] Task: binary\n",
      "\n",
      "[11:35:42] Start automl preset with listed constraints:\n",
      "[11:35:42] - time: 300.00 seconds\n",
      "[11:35:42] - CPU: 4 cores\n",
      "[11:35:42] - memory: 16 GB\n",
      "\n",
      "[11:35:42] Train data shape: (78440, 29)\n",
      "[11:35:46] Feats was rejected during automatic roles guess: []\n",
      "[11:35:46] Layer \u001b[1m1\u001b[0m train process start. Time left 295.86 secs\n",
      "[11:35:46] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:35:54] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7598962501666371\u001b[0m\n",
      "[11:35:54] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:35:54] Time left 287.49 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:36:06] \u001b[1mSelector_CatBoostGPU\u001b[0m fitting and predicting completed\n",
      "[11:36:07] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:36:19] Time limit exceeded after calculating fold(s) [0 1]\n",
      "[11:36:19] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m finished. score = \u001b[1m0.8086050357971936\u001b[0m\n",
      "[11:36:19] \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m fitting and predicting completed\n",
      "[11:36:19] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m ...\n",
      "[11:36:35] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m finished. score = \u001b[1m0.8064250733140045\u001b[0m\n",
      "[11:36:35] \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m fitting and predicting completed\n",
      "[11:36:35] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m ... Time budget is 129.04 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-2b3dac8f-5297-4895-a387-24293a2e2ec3\n",
      "INFO:optuna.study.study:Trial 0 finished with value: 0.8029775676138636 and parameters: {'max_depth': 3, 'max_leaves': 246, 'min_child_weight': 7.310215412599649e-05, 'reg_alpha': 8.029704871454908e-05, 'reg_lambda': 2.7553887877567553}. Best is trial 0 with value: 0.8029775676138636.\n",
      "INFO:optuna.study.study:Trial 1 finished with value: 0.8067346565898217 and parameters: {'max_depth': 4, 'max_leaves': 228, 'min_child_weight': 1.1742142803480238e-08, 'reg_alpha': 8.269558388663414e-08, 'reg_lambda': 1.1934219770913043e-06}. Best is trial 1 with value: 0.8067346565898217.\n",
      "INFO:optuna.study.study:Trial 2 finished with value: 0.8070254106956778 and parameters: {'max_depth': 4, 'max_leaves': 165, 'min_child_weight': 0.36901473764956844, 'reg_alpha': 5.428843755514162e-06, 'reg_lambda': 7.32228851960667e-06}. Best is trial 2 with value: 0.8070254106956778.\n",
      "INFO:optuna.study.study:Trial 3 finished with value: 0.8117717745775965 and parameters: {'max_depth': 7, 'max_leaves': 51, 'min_child_weight': 5.895315573626075e-07, 'reg_alpha': 1.687539330428219, 'reg_lambda': 0.02666590291022541}. Best is trial 3 with value: 0.8117717745775965.\n",
      "INFO:optuna.study.study:Trial 4 finished with value: 0.8069727827512748 and parameters: {'max_depth': 4, 'max_leaves': 22, 'min_child_weight': 0.11338699075595013, 'reg_alpha': 0.04005977144088293, 'reg_lambda': 1.0448237061959752e-06}. Best is trial 3 with value: 0.8117717745775965.\n",
      "INFO:optuna.study.study:Trial 5 finished with value: 0.8107290727282318 and parameters: {'max_depth': 5, 'max_leaves': 216, 'min_child_weight': 4.845519595814213e-07, 'reg_alpha': 1.1640982203543832e-05, 'reg_lambda': 0.10860611520028701}. Best is trial 3 with value: 0.8117717745775965.\n",
      "INFO:optuna.study.study:Trial 6 finished with value: 0.8026241083925306 and parameters: {'max_depth': 3, 'max_leaves': 215, 'min_child_weight': 0.003763999883958257, 'reg_alpha': 1.4674953465689633e-08, 'reg_lambda': 3.829355338296535e-06}. Best is trial 3 with value: 0.8117717745775965.\n",
      "INFO:optuna.study.study:Trial 7 finished with value: 0.8071119390262664 and parameters: {'max_depth': 4, 'max_leaves': 23, 'min_child_weight': 0.056254587306123906, 'reg_alpha': 0.0068450343620546205, 'reg_lambda': 0.02773596322059288}. Best is trial 3 with value: 0.8117717745775965.\n",
      "INFO:optuna.study.study:Trial 8 finished with value: 0.8032110139240252 and parameters: {'max_depth': 3, 'max_leaves': 244, 'min_child_weight': 0.2331580159252186, 'reg_alpha': 0.0008533755075363752, 'reg_lambda': 0.00014403013549761239}. Best is trial 3 with value: 0.8117717745775965.\n",
      "INFO:optuna.study.study:Trial 9 finished with value: 0.8071328760613132 and parameters: {'max_depth': 4, 'max_leaves': 221, 'min_child_weight': 1.3227164112935834, 'reg_alpha': 0.4392027989517867, 'reg_lambda': 6.173171986396101e-06}. Best is trial 3 with value: 0.8117717745775965.\n",
      "INFO:optuna.study.study:Trial 10 finished with value: 0.807204590298179 and parameters: {'max_depth': 4, 'max_leaves': 77, 'min_child_weight': 0.06126632936786799, 'reg_alpha': 0.12224000065244402, 'reg_lambda': 3.8812059680317756}. Best is trial 3 with value: 0.8117717745775965.\n",
      "INFO:optuna.study.study:Trial 11 finished with value: 0.8134714492790135 and parameters: {'max_depth': 7, 'max_leaves': 83, 'min_child_weight': 1.7284034140956053e-05, 'reg_alpha': 2.8191097737757853, 'reg_lambda': 1.2278794603105637e-08}. Best is trial 11 with value: 0.8134714492790135.\n",
      "INFO:optuna.study.study:Trial 12 finished with value: 0.8127331660490323 and parameters: {'max_depth': 7, 'max_leaves': 124, 'min_child_weight': 6.569152052751848e-07, 'reg_alpha': 1.4511287696161193, 'reg_lambda': 0.01631527776301119}. Best is trial 11 with value: 0.8134714492790135.\n",
      "INFO:optuna.study.study:Trial 13 finished with value: 0.8140496555050583 and parameters: {'max_depth': 7, 'max_leaves': 86, 'min_child_weight': 1.4017611603891682e-05, 'reg_alpha': 5.971539432105531, 'reg_lambda': 3.1972573644703376e-08}. Best is trial 13 with value: 0.8140496555050583.\n",
      "INFO:optuna.study.study:Trial 14 finished with value: 0.8139064553167554 and parameters: {'max_depth': 7, 'max_leaves': 117, 'min_child_weight': 2.8049553215333063e-05, 'reg_alpha': 7.095478913660622, 'reg_lambda': 1.6694877662768353e-08}. Best is trial 13 with value: 0.8140496555050583.\n",
      "INFO:optuna.study.study:Trial 15 finished with value: 0.8121045005901586 and parameters: {'max_depth': 6, 'max_leaves': 104, 'min_child_weight': 0.00013725345232339282, 'reg_alpha': 1.8338798600536472, 'reg_lambda': 1.638315014774324e-08}. Best is trial 13 with value: 0.8140496555050583.\n",
      "INFO:optuna.study.study:Trial 16 finished with value: 0.8133338420837176 and parameters: {'max_depth': 6, 'max_leaves': 134, 'min_child_weight': 0.0010522205612855245, 'reg_alpha': 4.119260845032726, 'reg_lambda': 1.0989728888206273e-08}. Best is trial 13 with value: 0.8140496555050583.\n",
      "INFO:optuna.study.study:Trial 17 finished with value: 0.8136305316107241 and parameters: {'max_depth': 6, 'max_leaves': 151, 'min_child_weight': 0.0029359991038929814, 'reg_alpha': 7.740201138298392, 'reg_lambda': 1.0750747940997549e-07}. Best is trial 13 with value: 0.8140496555050583.\n",
      "INFO:optuna.study.study:Trial 18 finished with value: 0.810237769873123 and parameters: {'max_depth': 6, 'max_leaves': 171, 'min_child_weight': 2.0925338872437246e-05, 'reg_alpha': 0.03025184938581918, 'reg_lambda': 1.5921421518171331e-07}. Best is trial 13 with value: 0.8140496555050583.\n",
      "INFO:optuna.study.study:Trial 19 finished with value: 0.8109508112571132 and parameters: {'max_depth': 6, 'max_leaves': 180, 'min_child_weight': 1.0146393027819031e-05, 'reg_alpha': 0.07457487687101295, 'reg_lambda': 2.099065977990143e-07}. Best is trial 13 with value: 0.8140496555050583.\n",
      "INFO:optuna.study.study:Trial 20 finished with value: 0.8123176947215599 and parameters: {'max_depth': 7, 'max_leaves': 63, 'min_child_weight': 7.02567202944431, 'reg_alpha': 0.13751396796096974, 'reg_lambda': 6.363093817638442e-05}. Best is trial 13 with value: 0.8140496555050583.\n",
      "INFO:optuna.study.study:Trial 22 finished with value: 0.8133849046423228 and parameters: {'max_depth': 7, 'max_leaves': 112, 'min_child_weight': 0.003948733826656869, 'reg_alpha': 9.270845617126525, 'reg_lambda': 1.0211956770607667e-07}. Best is trial 13 with value: 0.8140496555050583.\n",
      "INFO:optuna.study.study:Trial 21 finished with value: 0.8144834630442987 and parameters: {'max_depth': 7, 'max_leaves': 99, 'min_child_weight': 6.499240879905705, 'reg_alpha': 9.66791668565932, 'reg_lambda': 3.57821067118035e-05}. Best is trial 21 with value: 0.8144834630442987.\n",
      "INFO:optuna.study.study:Trial 24 finished with value: 0.8116629558054901 and parameters: {'max_depth': 5, 'max_leaves': 96, 'min_child_weight': 0.0005861012119843163, 'reg_alpha': 0.4876897533382675, 'reg_lambda': 0.0008549082427704394}. Best is trial 21 with value: 0.8144834630442987.\n",
      "INFO:optuna.study.study:Trial 23 finished with value: 0.8131702674208892 and parameters: {'max_depth': 6, 'max_leaves': 144, 'min_child_weight': 0.0004132129317263184, 'reg_alpha': 6.576355506478594, 'reg_lambda': 5.998106134317039e-08}. Best is trial 21 with value: 0.8144834630442987.\n",
      "INFO:optuna.study.study:Trial 25 finished with value: 0.8118417277554397 and parameters: {'max_depth': 7, 'max_leaves': 48, 'min_child_weight': 0.022757126714039375, 'reg_alpha': 0.7510687014958001, 'reg_lambda': 5.402713267275197e-05}. Best is trial 21 with value: 0.8144834630442987.\n",
      "INFO:optuna.study.study:Trial 26 finished with value: 0.8114209406386953 and parameters: {'max_depth': 7, 'max_leaves': 47, 'min_child_weight': 0.019493034008272295, 'reg_alpha': 0.5197292755295303, 'reg_lambda': 3.110956520652541e-05}. Best is trial 21 with value: 0.8144834630442987.\n",
      "INFO:optuna.study.study:Trial 27 finished with value: 0.8111248788966182 and parameters: {'max_depth': 5, 'max_leaves': 84, 'min_child_weight': 4.802142513383662, 'reg_alpha': 0.30592336606523346, 'reg_lambda': 5.226896455514131e-07}. Best is trial 21 with value: 0.8144834630442987.\n",
      "INFO:optuna.study.study:Trial 28 finished with value: 0.8121079004124384 and parameters: {'max_depth': 5, 'max_leaves': 118, 'min_child_weight': 1.8289527680376634, 'reg_alpha': 8.968429075510674, 'reg_lambda': 5.827018112088482e-07}. Best is trial 21 with value: 0.8144834630442987.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:optuna.study.study:Trial 29 finished with value: 0.8117571153918434 and parameters: {'max_depth': 7, 'max_leaves': 117, 'min_child_weight': 1.2934137708544902, 'reg_alpha': 0.014749516672418812, 'reg_lambda': 3.3196781445339353e-08}. Best is trial 21 with value: 0.8144834630442987.\n",
      "INFO:optuna.study.study:Trial 30 finished with value: 0.8109544393648219 and parameters: {'max_depth': 7, 'max_leaves': 96, 'min_child_weight': 0.00010541119113586934, 'reg_alpha': 0.009437144333572341, 'reg_lambda': 3.529036060300029e-08}. Best is trial 21 with value: 0.8144834630442987.\n",
      "INFO:optuna.study.study:Trial 31 finished with value: 0.812774534629962 and parameters: {'max_depth': 6, 'max_leaves': 98, 'min_child_weight': 0.00010102597023848029, 'reg_alpha': 1.3286294565999424, 'reg_lambda': 3.495173917149691e-08}. Best is trial 21 with value: 0.8144834630442987.\n",
      "INFO:optuna.study.study:Trial 32 finished with value: 0.8134080266950459 and parameters: {'max_depth': 6, 'max_leaves': 151, 'min_child_weight': 0.0023251753051056995, 'reg_alpha': 9.205699591425471, 'reg_lambda': 5.207337251432195e-08}. Best is trial 21 with value: 0.8144834630442987.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:38:49] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m completed\n",
      "[11:38:49] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m ...\n",
      "[11:39:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m finished. score = \u001b[1m0.8086180548776082\u001b[0m\n",
      "[11:39:00] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m fitting and predicting completed\n",
      "[11:39:00] Time left 102.04 secs\n",
      "\n",
      "[11:39:00] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "[11:39:00] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:39:00] Blending: Optimization starts with equal weights and score 0.8060023416557095\n",
      "[11:39:00] Blending, iter 0: score = 0.8098392762983398, weights = [0.         0.36816138 0.19495766 0.4368809 ]\n",
      "[11:39:00] Blending, iter 1: score = 0.8098452508016799, weights = [0.         0.31726137 0.23606798 0.44667065]\n",
      "[11:39:01] Blending, iter 2: score = 0.8098458652102111, weights = [0.         0.33183777 0.2287944  0.4393679 ]\n",
      "[11:39:01] Blending, iter 3: score = 0.8098458652102111, weights = [0.         0.33183777 0.2287944  0.4393679 ]\n",
      "[11:39:01] No score update. Terminated\n",
      "[11:39:01] \u001b[1mAutoml preset training completed in 199.01 seconds\u001b[0m\n",
      "\n",
      "[11:39:01] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.33184 * (2 averaged models Lvl_0_Pipe_1_Mod_0_CatBoostGPU) +\n",
      "\t 0.22879 * (5 averaged models Lvl_0_Pipe_1_Mod_2_XGB) +\n",
      "\t 0.43937 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_XGB) \n",
      "\n",
      "CPU times: user 4min 35s, sys: 1min 10s, total: 5min 45s\n",
      "Wall time: 3min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# task = Task(task_types['higgs.csv'], device='mgpu')\n",
    "\n",
    "automl = TabularAutoMLGPU(\n",
    "    task=Task('binary', device='mgpu'),\n",
    "    timeout=TIMEOUT,\n",
    "    config_path='./data/dp.yml',\n",
    "    client=client,\n",
    "    general_params = {'parallel_folds': True} # stands for compute parallel. True for DataParallel\n",
    ")\n",
    "\n",
    "\n",
    "oof_pred = automl.fit_predict(tr_data, roles = roles, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_pred = automl.predict(te_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42730862],\n",
       "       [0.38947627],\n",
       "       [0.8526692 ],\n",
       "       ...,\n",
       "       [0.6104051 ],\n",
       "       [0.8978532 ],\n",
       "       [0.67152834]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.predict(te_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOLDOUT score: 0.8122351060285518\n"
     ]
    }
   ],
   "source": [
    "auc_test = roc_auc_score(te_data[data_info_['target']].values, te_pred.data[:, 0])\n",
    "print(f'HOLDOUT score: {auc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.14221,
     "end_time": "2021-06-22T20:35:48.782561",
     "exception": false,
     "start_time": "2021-06-22T20:35:48.640351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Additional materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.147943,
     "end_time": "2021-06-22T20:35:49.074531",
     "exception": false,
     "start_time": "2021-06-22T20:35:48.926588",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- [Official LightAutoML github repo](https://github.com/sberbank-ai-lab/LightAutoML)\n",
    "- [LightAutoML documentation](https://lightautoml.readthedocs.io/en/latest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-23.02",
   "language": "python",
   "name": "rapids-23.02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1531.539656,
   "end_time": "2021-06-22T20:35:52.076563",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-22T20:10:20.536907",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
